# =============================================================================
# main.py  ä¸»å‡½æ•°
# =============================================================================
# main.py
"""
è”é‚¦å­¦ä¹ åé—¨æ”»å‡»æ£€æµ‹ä¸»å®éªŒè„šæœ¬
å®ç°äº†å®Œæ•´çš„æ”»å‡»ç±»å‹å’Œæ£€æµ‹æ–¹æ³•
"""

import os
import sys
import time
import torch
import numpy as np
import random
from pathlib import Path

# è®¾ç½®é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.absolute()
sys.path.insert(0, str(PROJECT_ROOT))


def set_seed(seed):
    """è®¾ç½®éšæœºç§å­ç¡®ä¿å®éªŒå¯é‡å¤"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def main():
    # åˆå§‹åŒ–é…ç½®
    from config import Config
    config = Config()
    set_seed(config.seed)

    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs(config.results_dir, exist_ok=True)
    os.makedirs(f"{config.results_dir}/logs", exist_ok=True)
    os.makedirs(f"{config.results_dir}/models", exist_ok=True)

    # è®¾ç½®æ—¥å¿—
    from utils.logger import setup_logger
    logger = setup_logger("federated_backdoor", f"{config.results_dir}/logs")

    logger.info("=" * 80)
    logger.info("ğŸ¯ è”é‚¦å­¦ä¹ åé—¨æ”»å‡»æ£€æµ‹å®éªŒå¼€å§‹")
    logger.info("=" * 80)

    # æ£€æŸ¥ç¯å¢ƒ
    logger.info(f"è®¾å¤‡: {config.device}")
    if torch.cuda.is_available():
        logger.info(f"GPU: {torch.cuda.get_device_name(0)}")
        logger.info(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory // 1024 ** 3} GB")

    # 1. å‡†å¤‡æ•°æ®
    logger.info("ğŸ“Š åŠ è½½CIFAR-10æ•°æ®é›†...")
    from data.loader import get_cifar10_loaders
    from data.federated import FederatedDataset

    train_loader, test_loader, trainset = get_cifar10_loaders(config)

    fed_dataset = FederatedDataset(trainset, config)
    logger.info(f"è”é‚¦æ•°æ®åˆ†å‰²å®Œæˆ: {config.num_clients}ä¸ªå®¢æˆ·ç«¯")
    logger.info(f"æ•°æ®åˆ†å¸ƒ: {'Non-IID' if config.non_iid else 'IID'}")

    # 2. åˆ›å»ºç»¼åˆæ”»å‡»å™¨
    from attack.backdoor import ComprehensiveBackdoorAttack

    logger.info(f"ğŸ­ åˆå§‹åŒ–{config.attack_type}æ”»å‡»å™¨...")
    logger.info(f"æ”»å‡»å‚æ•°:")
    logger.info(f"  - è§¦å‘å™¨ç±»å‹: {config.trigger_pattern}")
    logger.info(f"  - è§¦å‘å™¨å¤§å°: {config.trigger_size}x{config.trigger_size}")
    logger.info(f"  - è§¦å‘å™¨ä½ç½®: {config.trigger_position}")
    logger.info(f"  - æŠ•æ¯’ç‡: {config.poison_rate}")
    logger.info(f"  - ç›®æ ‡æ ‡ç­¾: {config.target_label}")
    logger.info(f"  - ç¼©æ”¾å› å­: {config.scale_factor}")

    # 3. è”é‚¦å­¦ä¹ è®­ç»ƒ
    logger.info("ğŸ”— å¼€å§‹è”é‚¦å­¦ä¹ è®­ç»ƒ...")
    from federated.server import FederatedServer
    from models.resnet import ResNet20

    server = FederatedServer(fed_dataset, config, ComprehensiveBackdoorAttack)

    # è®°å½•è®­ç»ƒå¼€å§‹æ—¶é—´
    training_start_time = time.time()
    server.train()
    training_end_time = time.time()

    # è·å–æ”»å‡»ç»Ÿè®¡
    attack_stats = server.get_attack_statistics()
    logger.info(f"ğŸ“ˆ æ”»å‡»ç»Ÿè®¡: {attack_stats}")
    logger.info(f"â±ï¸ è®­ç»ƒè€—æ—¶: {(training_end_time - training_start_time) / 60:.1f}åˆ†é’Ÿ")

    logger.info("è”é‚¦å­¦ä¹ è®­ç»ƒå®Œæˆ")

    # 4. è¯„ä¼°å…¨å±€æ¨¡å‹
    logger.info("ğŸ” è¯„ä¼°å…¨å±€æ¨¡å‹æ€§èƒ½...")
    global_model = ResNet20(config.num_classes)
    global_model.load_state_dict(server.global_model)
    global_model.to(config.device)

    from utils.metrics import evaluate_model, evaluate_attack_success_rate

    clean_acc = evaluate_model(global_model, test_loader, config.device)

    # åˆ›å»ºæµ‹è¯•ç”¨æ”»å‡»å™¨
    test_attacker = ComprehensiveBackdoorAttack(config)
    asr = evaluate_attack_success_rate(global_model, test_loader, test_attacker, config.device)

    logger.info(f"å…¨å±€æ¨¡å‹æ€§èƒ½: æ¸…æ´å‡†ç¡®ç‡={clean_acc:.4f}, æ”»å‡»æˆåŠŸç‡={asr:.4f}")

    # è¯¦ç»†çš„æ”»å‡»æ•ˆæœåˆ†æ
    logger.info("=" * 50)
    logger.info("ğŸ¯ æ”»å‡»æ•ˆæœè¯¦ç»†åˆ†æ:")
    logger.info(f"æ”»å‡»ç±»å‹: {config.attack_type}")
    logger.info(f"è§¦å‘å™¨æ¨¡å¼: {config.trigger_pattern}")
    logger.info(f"æ¶æ„å®¢æˆ·ç«¯å‚ä¸ç‡: {attack_stats['malicious_participation']:.2%}")

    if asr > 0.5:
        logger.info("ğŸš¨ æ”»å‡»æˆåŠŸï¼åé—¨å·²è¢«æ¤å…¥å…¨å±€æ¨¡å‹")
        attack_status = "æˆåŠŸ"
    elif asr > 0.1:
        logger.info("âš ï¸ æ”»å‡»éƒ¨åˆ†æˆåŠŸï¼Œå­˜åœ¨ä¸€å®šçš„åé—¨æ•ˆæœ")
        attack_status = "éƒ¨åˆ†æˆåŠŸ"
    else:
        logger.info("âœ… æ”»å‡»åŸºæœ¬å¤±è´¥ï¼Œæ¨¡å‹ç›¸å¯¹å®‰å…¨")
        attack_status = "å¤±è´¥"
    logger.info("=" * 50)

    # 5. ç”ŸæˆæŒä¹…å›¾
    logger.info("ğŸ”® ç”ŸæˆæŒä¹…å›¾ç‰¹å¾...")
    benign_models, malicious_models = server.get_models_for_analysis()

    # å¹³è¡¡æ ·æœ¬æ•°é‡
    min_samples = min(len(benign_models), len(malicious_models))
    if min_samples < 10:
        logger.warning(f"âš ï¸ æ ·æœ¬æ•°é‡è¿‡å°‘: è‰¯æ€§={len(benign_models)}, æ¶æ„={len(malicious_models)}")
        logger.warning("å°è¯•é‡å¤æ ·æœ¬ä»¥å¢åŠ æ•°æ®é‡...")

        # å¦‚æœæ ·æœ¬å¤ªå°‘ï¼Œé‡å¤æ ·æœ¬
        while len(benign_models) < 20:
            additional_samples = min(len(benign_models), 20 - len(benign_models))
            benign_models.extend(benign_models[:additional_samples])
        while len(malicious_models) < 20:
            additional_samples = min(len(malicious_models), 20 - len(malicious_models))
            malicious_models.extend(malicious_models[:additional_samples])

    # é™åˆ¶æ ·æœ¬æ•°é‡é¿å…è®¡ç®—è¿‡ä¹…
    benign_models = benign_models[:30]
    malicious_models = malicious_models[:30]

    logger.info(f"æ”¶é›†æ¨¡å‹: {len(benign_models)}ä¸ªè‰¯æ€§, {len(malicious_models)}ä¸ªæ¶æ„")

    from persistence.calculator import PersistenceCalculator
    from persistence.diagram import DiagramGenerator

    persistence_calc = PersistenceCalculator(config)
    diagram_gen = DiagramGenerator(persistence_calc)

    logger.info("å¼€å§‹ç”Ÿæˆè‰¯æ€§æ¨¡å‹çš„ç‰¹å¾...")
    persistence_start_time = time.time()

    benign_diagrams = diagram_gen.generate_diagrams(benign_models, test_loader)

    logger.info("å¼€å§‹ç”Ÿæˆæ¶æ„æ¨¡å‹çš„ç‰¹å¾...")
    malicious_diagrams = diagram_gen.generate_diagrams(malicious_models, test_loader)

    persistence_end_time = time.time()
    logger.info(f"æ¶æ„æ¨¡å‹çš„ç‰¹å¾ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {(persistence_end_time - persistence_start_time) / 60:.1f}åˆ†é’Ÿ")

    # 6. è®­ç»ƒæ£€æµ‹å™¨
    logger.info("ğŸ›¡ï¸ è®­ç»ƒåˆ†ç±»å™¨...")
    from detection.classifier import PDClassifier

    detector = PDClassifier(config)
    detection_start_time = time.time()

    metrics = detector.train_classifier(benign_diagrams, malicious_diagrams)

    detection_end_time = time.time()
    logger.info(f"æ£€æµ‹å™¨è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {(detection_end_time - detection_start_time) / 60:.1f}åˆ†é’Ÿ")

    # 7. ç»¼åˆç»“æœåˆ†æ
    logger.info("=" * 80)
    logger.info("ğŸ“Š å®éªŒç»“æœæ€»ç»“:")
    logger.info("=" * 80)

    # æ€§èƒ½æŒ‡æ ‡
    logger.info("ğŸ¯ æ€§èƒ½æŒ‡æ ‡:")
    logger.info(f"  æ£€æµ‹å‡†ç¡®ç‡: {metrics['accuracy']:.4f}")
    logger.info(f"  æ£€æµ‹å¬å›ç‡: {metrics['recall']:.4f}")
    logger.info(f"  æ£€æµ‹F1åˆ†æ•°: {metrics['f1_score']:.4f}")
    logger.info(f"  æ¸…æ´å‡†ç¡®ç‡: {clean_acc:.4f}")
    logger.info(f"  æ”»å‡»æˆåŠŸç‡: {asr:.4f}")

    # æ”»å‡»åˆ†æ
    logger.info("ğŸ­ æ”»å‡»åˆ†æ:")
    logger.info(f"  æ”»å‡»ç±»å‹: {config.attack_type}")
    logger.info(f"  æ”»å‡»çŠ¶æ€: {attack_status}")
    logger.info(f"  è§¦å‘å™¨æ•ˆæœ: {'æœ‰æ•ˆ' if asr > 0.3 else 'ä¸€èˆ¬' if asr > 0.1 else 'æ— æ•ˆ'}")

    # æ£€æµ‹åˆ†æ
    detection_effectiveness = "ä¼˜ç§€" if metrics['accuracy'] > 0.9 else "è‰¯å¥½" if metrics['accuracy'] > 0.8 else "ä¸€èˆ¬"
    logger.info("ğŸ›¡ï¸ æ£€æµ‹åˆ†æ:")
    logger.info(f"  æ£€æµ‹æ•ˆæœ: {detection_effectiveness}")
    logger.info(f"  è¯¯æŠ¥ç‡: {1 - metrics['accuracy']:.3f}")
    logger.info(f"  æ£€æµ‹å¯é æ€§: {'é«˜' if metrics['f1_score'] > 0.9 else 'ä¸­ç­‰' if metrics['f1_score'] > 0.8 else 'ä½'}")

    # æ—¶é—´ç»Ÿè®¡
    total_time = (training_end_time - training_start_time) + (persistence_end_time - persistence_start_time) + (
            detection_end_time - detection_start_time)
    logger.info("â±ï¸ æ—¶é—´ç»Ÿè®¡:")
    logger.info(f"  è”é‚¦è®­ç»ƒ: {(training_end_time - training_start_time) / 60:.1f}åˆ†é’Ÿ")
    logger.info(f"  ç‰¹å¾ç”Ÿæˆ: {(persistence_end_time - persistence_start_time) / 60:.1f}åˆ†é’Ÿ")
    logger.info(f"  æ£€æµ‹è®­ç»ƒ: {(detection_end_time - detection_start_time) / 60:.1f}åˆ†é’Ÿ")
    logger.info(f"  æ€»è€—æ—¶: {total_time / 60:.1f}åˆ†é’Ÿ")

    # 8. ä¿å­˜ç»“æœ
    logger.info("ğŸ’¾ ä¿å­˜å®éªŒç»“æœ...")
    results = {
        'detection_accuracy': metrics['accuracy'],
        'detection_recall': metrics['recall'],
        'detection_f1': metrics['f1_score'],
        'clean_accuracy': clean_acc,
        'attack_success_rate': asr,
        'attack_status': attack_status,
        'attack_type': config.attack_type,
        'trigger_pattern': config.trigger_pattern,
        'attack_stats': attack_stats,
        'training_time_minutes': (training_end_time - training_start_time) / 60,
        'total_time_minutes': total_time / 60,
        'config': vars(config)
    }

    # ä¿å­˜æ¨¡å‹å’Œç»“æœ
    save_path = f"{config.results_dir}/models/final_models.pth"
    torch.save({
        'global_model': server.global_model,
        'detector': detector.model.state_dict(),
        'results': results,
        'config': vars(config),
        'benign_diagrams': benign_diagrams,
        'malicious_diagrams': malicious_diagrams
    }, save_path)

    # ä¿å­˜ç®€åŒ–çš„ç»“æœæ–‡ä»¶
    import json
    results_summary = {k: v for k, v in results.items() if k != 'config'}
    with open(f"{config.results_dir}/results_summary.json", 'w') as f:
        json.dump(results_summary, f, indent=2)

    logger.info(f"å®éªŒç»“æœå·²ä¿å­˜åˆ°: {save_path}")
    logger.info("å®éªŒå®Œæˆï¼")

    return results


if __name__ == "__main__":
    """
    åœ¨PyCharmä¸­è¿è¡Œæ­¤è„šæœ¬çš„æ­¥éª¤:
    
    1. ç¡®ä¿æ‰€æœ‰ä¾èµ–å·²å®‰è£…
    2. å³é”®ç‚¹å‡»æ­¤æ–‡ä»¶ï¼Œé€‰æ‹©"Run 'main'"
    3. æˆ–è€…åœ¨PyCharmç»ˆç«¯ä¸­è¿è¡Œ: python main.py
    4. æŸ¥çœ‹results/ç›®å½•ä¸‹çš„ç»“æœæ–‡ä»¶
    """

    try:
        start_time = time.time()
        results = main()
        end_time = time.time()

        print("\n" + "ğŸ‰" * 20)
        print("å®éªŒæˆåŠŸå®Œæˆï¼")
        print("ğŸ‰" * 20)
        print(f"ğŸ“Š æ£€æµ‹å‡†ç¡®ç‡: {results['detection_accuracy']:.3f}")
        print(f"ğŸ“Š æ¸…æ´å‡†ç¡®ç‡: {results['clean_accuracy']:.3f}")
        print(f"ğŸ“Š æ”»å‡»æˆåŠŸç‡: {results['attack_success_rate']:.3f}")
        print(f"ğŸ“Š æ”»å‡»çŠ¶æ€: {results['attack_status']}")
        print(f"â±ï¸ æ€»è€—æ—¶: {(end_time - start_time) / 60:.1f}åˆ†é’Ÿ")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: ./results/")
        print("ğŸ‰" * 20)

    except KeyboardInterrupt:
        print("\nâ¹ï¸ å®éªŒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ å®éªŒå¼‚å¸¸ç»ˆæ­¢: {e}")
        import traceback

        traceback.print_exc()
        print("\nğŸ” è¯·æ£€æŸ¥:")
        print("1. æ‰€æœ‰ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…")
        print("2. CUDAç¯å¢ƒæ˜¯å¦é…ç½®æ­£ç¡®")
        print("3. æ•°æ®é›†æ˜¯å¦ä¸‹è½½å®Œæˆ")
        print("4. ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³")
